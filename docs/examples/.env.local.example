# Shopify Nano-SRE - Local Development Configuration
# Copy this file to .env for local development

# ============================================
# STORE CONFIGURATION
# ============================================

# Required: Your Shopify store URL for local testing
# Use a development store or staging environment for local testing
STORE_URL=https://your-dev-store.myshopify.com

# Optional: Shopify Admin API key (required for Shopify Doctor skill)
# Get from: Shopify Admin > Settings > Apps and integrations > Develop apps
# For local dev, use a development store API key
SHOPIFY_ADMIN_API_KEY=

# ============================================
# LLM CONFIGURATION
# ============================================

# LLM Provider for local development
# Options: openai, anthropic, ollama
# Recommended for local: ollama (no API costs)
LLM_PROVIDER=ollama

# API key for the LLM provider (not needed for ollama)
# For OpenAI: Get from https://platform.openai.com/api-keys
# For Anthropic: Get from https://console.anthropic.com/
LLM_API_KEY=

# Model name for LLM
# OpenAI: gpt-4, gpt-4-turbo, gpt-3.5-turbo
# Anthropic: claude-3-opus, claude-3-sonnet, claude-3-haiku
# Ollama: mistral, llama2, codellama, etc.
LLM_MODEL=mistral

# Ollama base URL (only needed if running Ollama on a different machine)
# Default: http://localhost:11434
OLLAMA_BASE_URL=http://localhost:11434

# ============================================
# ALERTING
# ============================================

# Optional: Webhook URL for alerts
# For local testing, you can use a service like webhook.site
# Example: https://webhook.site/your-unique-id
ALERT_WEBHOOK_URL=

# ============================================
# MONITORING & STORAGE
# ============================================

# Interval in minutes between checks
# For local development, use a longer interval to avoid rate limits
CHECK_INTERVAL_MINUTES=60

# Path to SQLite database file
# Use a local path for development
SQLITE_DB_PATH=./data/nano_sre_dev.db

# ============================================
# PRIVACY & SECURITY
# ============================================

# Enable PII redaction in logs and reports
# For local development, you may want to disable this for easier debugging
REDACT_PII=false

# Enable blurring of sensitive selectors in screenshots
# For local development, usually set to false
SCREENSHOT_BLUR_ENABLED=false

# ============================================
# DEVELOPMENT SETTINGS
# ============================================

# Log level for development
# Options: DEBUG, INFO, WARNING, ERROR, CRITICAL
LOG_LEVEL=DEBUG

# Enable debug mode (shows browser UI during tests)
# Set to true to see the browser window during monitoring
HEADLESS=false

# Browser viewport size for screenshots
VIEWPORT_WIDTH=1920
VIEWPORT_HEIGHT=1080

# Network conditions simulation
# Options: none, slow3g, fast3g
NETWORK_THROTTLE=none

# Device emulation
# Options: none, iPhone 17 Pro, Pixel 5, etc.
DEVICE_EMULATION=none

# ============================================
# PLAYWRIGHT SETTINGS
# ============================================

# Browser to use
# Options: chromium, firefox, webkit
BROWSER=chromium

# Enable video recording for debugging
RECORD_VIDEO=false

# Enable trace recording for debugging
RECORD_TRACE=false

# ============================================
# LOCAL TESTING NOTES
# ============================================

# Setup Instructions for Local Development:
#
# 1. Install Ollama (recommended for free local LLM):
#    brew install ollama  # macOS
#    # or visit https://ollama.ai for other platforms
#
# 2. Pull a model:
#    ollama pull mistral
#
# 3. Start Ollama service:
#    ollama serve
#
# 4. Install Playwright browsers:
#    playwright install chromium
#
# 5. Create data directory:
#    mkdir -p data
#
# 6. Run your first check:
#    nano-sre audit --url https://your-dev-store.myshopify.com
#
# Alternative: Use OpenAI for better quality (requires API key):
#    - Set LLM_PROVIDER=openai
#    - Set LLM_API_KEY=sk-your-key-here
#    - Set LLM_MODEL=gpt-4
